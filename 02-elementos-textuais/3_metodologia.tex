\chapter{Metodologia}
\label{chap:metodologia}

\epigraph{Pica pau voa é duvidando do ar}{Riobaldo, em "Grande Sertão: Veredas"}


% origem do d-optimas no bimasco 
% retomar os objetivos do trabalho: criar um sistema resiliente, 
O capítulo anterior apresentou algumas arquiteturas e \textit{frameworks} para resolução de problemas de otimização que podem ser executadas em um \textit{cluster}. Entre elas, se destaca a arquitetura D-Optimas, baseada no sistema de atores. Do ponto de vista de sistemas distribuídos, essa arquitetura apresenta algumas dificuldades para executá-la em um \textit{cluster} com mais de dois nós. Além disso, é possível observar também alguns aspectos da modelagem que tornam a configuração da arquitetura muito acoplada ao problema de otimização, principalmente no que diz respeito aos parâmetros das regiões.

Deste modo, o presente trabalho se dedica a propor melhorias na arquitetura D-Optimas, a fim de tornar o comportamento das regiões menos dependente de algum conhecimento prévio do problema e também possibilitar a escalabilidade horizontal da arquitetura. O presente capítulo é dedicado a expor a metodologia utilizada para atingir os objetivos propostos no \autoref{chap:introducao}. A próxima seção apresenta as hipóteses que guiam este trabalho. Em seguida, na \autoref{sec:metodo} é apresentado o método utilizado para por as hipóteses à prova. A \autoref{sec:premissas} apresenta as premissas que podem ser assumidas no decorrer da metodologia, e por fim, a \autoref{sec:experimentos} apresenta os experimentos que serão executados para verificar as hipóteses.


\section{Hipóteses}
\label{sec:hipoteses}
% retomar as hipoteses dos trabalhos anteriores
Dentre os trabalhos que envolveram a arquitetura D-Optimas e sua antecessora, o Bimasco, se destacam as contribuições mais recentes de \citeonline{marcus2015} e \citeonline{pacheco}. As hipóteses levantadas e testadas por \citeonline{marcus2015} foram de que a diversidade de agentes poderia favorecer a exploração do espaço de busca e que a segregação das soluções em regiões em conjunto com um mecanismo de aprendizagem levaria os agentes a buscarem soluções de melhor qualidade. Por sua vez, \citeonline{pacheco} levantou a hipótese de que a mudança para o modelo de atores permitiria que a arquitetura escalasse de maneira vertical, em um único computador, e de maneira horizontal, ao longo de um \textit{cluster}. De maneira mais geral, a hipótese que motiva a construção da arquitetura é de que nenhuma meta-heurística particular é capaz de encontrar bons resultados para todos os tipos de problemas, porém uma combinação adequada delas poderia gerar resultados melhores. 

% retomar o meu problema
Sendo assim, torna-se necessário conduzir um estudo mais  detalhado do comportamento da arquitetura ao longo de uma simulação, com a presença de uma maior diversidade de meta-heurísticas. É também necessário verificar o desempenho da D-Optimas em um \textit{cluster} com vários computadores, onde a influência da rede é crítica e onde a escalabilidade horizontal poderia ser melhor verificada. Além disso, a implementação de um conjunto muito restrito de meta-heurísticas impediu uma investigação mais detalhada do efeito da diversidade no processo de busca. Espera-se que, corrigidas as falhas discutidas no capítulo anterior e adicionando novas meta-heurísticas, seja possível avaliar com maior robustez algumas destas hipóteses. 

% introduzir a minha hipótese
A primeira hipótese que se pode formular no presente trabalho é que a versão da arquitetura produzida exibe um comportamento convergente em torno do valor conhecido da função objetivo dos problemas propostos na literatura. A segunda hipótese formulada é que o aumento do número de nós não acarreta em perda de desempenho ou diminuição da taxa de convergência da arquitetura. E por fim, é possível revisitar a hipótese levantada por \citeonline{marcus2015},de que, ao inserir diversidade de estratégias
de busca, combinada com um sistema de memória e um mecanismo de colaboração entre
os agentes, a arquitetura é capaz de produzir soluções de melhor qualidade para diferentes problemas.


\section{Método}
\label{sec:metodo}

Como já foi dito, o objetivo do presente trabalho é construir uma nova versão da arquitetura  D-Optimas, baseado na versão proposta por \citeonline{pacheco}. Este sistema multi-agentes deve ser construído sem um controle central, utilizando técnicas e ferramentas de sistemas distribuídos, que permitam a sua execução em um \textit{cluster} com um número arbitrário de nós. Nesta nova versão, as regiões devem funcionar de maneira independente dos dados do problema objeto de estudo, necessitando o mínimo de conhecimento prévio acerca dele para configurar a arquitetura. Também pretende-se adicionar novas meta-heurísticas à arquitetura, adaptando-as para funcionar num contexto distribuído, a fim de poder obter resultados confiáveis para avaliar o desempenho do sistema em diferentes problemas de otimização. 

Dito isto, a metodologia estabelecida para atingir os objetivos e por as hipóteses à prova consiste em, inicialmente, compreender a atual versão da arquitetura, desenvolvida por \citeonline{pacheco} sobre o \textit{toolkit akka}, e verificar quais pontos têm dificultado sua execução em um \textit{cluster} com mais de dois nós. 

Para suplantar essas dificuldades, é necessário, em seguida, estudar os recursos do \textit{toolkit akka}, em especial, as ferramentas que compõem o \textit{akka-cluster}, o qual implementa todas as funcionalidades e recursos essenciais para o desenvolvimento de um sistema distribuído. A biblioteca \textit{akka-cluster} foi escolhida em detrimento de várias outras alternativas pois a última versão da arquitetura já está implementada no modelo de atores, adotado na D-Optimas. Assim, adotar esta implementação dos algoritmos clássicos de sistemas distribuídos, tais como descobrimento de nós e eleição de líder, parece uma escolha natural e que leva ao menor retrabalho.

Após compreender a arquitetura D-Optimas e as ferramentas necessárias para a implementação de um sistema distribuído, é necessário refatorar a arquitetura para incluir os recursos do \textit{akka-cluster}. As modificações nos protocolos de funcionamento serão inevitáveis, pois apesar de alguns atores supervisores já existirem, eles não foram preparados para chegar a um consenso sobre, por exemplo, para qual região uma solução deveria ir em um sistema distribuído. Nesta nova versão da arquitetura, atores supervisores do mesmo tipo precisarão manter uma comunicação frequente e um estado distribuído da aplicação, permitindo ao sistema como um todo ser resiliente a falhas.

Para além de refatorar a comunicação entre os atores supervisores, será necessário detalhar e implementar o funcionamento das regiões em concordância com os objetivos aqui propostos. A primeira versão das regiões implementada por \citeonline{marcus2015} estava fortemente amarrada a um conhecimento prévio do problema. O que se propõe aqui é aprimorar a implementação, desvinculando-a dos dados do problema, e estudar o efeito macro dos comportamentos de fissão e fusão no comportamento/resultados gerados pela arquitetura. Além disto, \citeonline{marcus2015} apontou como uma oportunidade de trabalho futuro a inserção de novas meta-heurísticas a arquitetura, uma vez que a escassez delas pode ter influenciado na performance de seus resultados. Assim, é necessário revisar a literatura, encontrar meta-heurísticas que sejam relevantes para este trabalho, estudar o seu funcionamento, adaptá-las ao contexto de um sistema multi-agente genérico no que diz respeito à representação dos problemas, e implementá-las neste sistema.

Para validar as hipóteses levantadas na seção anterior, experimentos serão executados e dados serão coletados, tratados e analisados. Todavia, num sistema distribuído e assíncrono, que opera por meio de troca de mensagens, a coleta de dados confiável, que preserva a sequência temporal dos mesmos está longe de ser tarefa trivial, como é em outros cenários. Neste contexto, será necessário propor e implementar um sistema de persistência e coleta de dados adequado à um sistema distribuído. Neste tipo de sistema as entidades podem e, de fato migram de um nó para outro. Portanto, manter ativa e funcional uma conexão com um banco de dados centralizado, e muitas das vezes remoto, representa não apenas uma tarefa árdua, como também um possível gargalo/ponto único de falha. Além disto, como a escrita no banco de dados é uma operação muito mais dominante na D-Optimas em comparação com a leitura, é possível abrir mão dos princípios de ACID\footnote{Sigla  para Atomicidade, Consistência, Isolamento e Durabilidade. Estas quatro propriedades são fortemente garantidas em bancos de dados relacionais, o que permite o desenvolvimento de aplicações confiáveis para o usuário final. No contexto do desenvolvimento de sistemas distribuídos, é comum abandonar a premissa de consistência e adotar uma consistência eventual, onde, em algum momento no tempo, todas as instâncias do banco de dados terão o mesmo conjunto de dados.} e utilizar um banco de dados distribuído não-SQL. Ao longo da execução, os agentes e regiões escrevem no banco de dados os eventos relevantes (por exemplo, a produção ou recebimento de uma nova solução, uma operação de fusão ou fissão), e ao final da execução, esses dados são extraídos pela arquitetura, recebendo neste ponto um primeiro tratamento, como por exemplo, a ordenação, agrupamento e remoção de eventuais dados duplicados. 

Ao final deste tratamento, os dados são salvos em um conjunto de arquivos texto do tipo \textit{csv}. Para cada série de dados extraída, e para cada entidade, um novo arquivo é criado, \textit{i.e}, há pelo menos um arquivo para cada região/agente na simulação. Os dados extraídos são: as soluções produzidas por cada agente e o intervalo de tempo para produzir cada solução, as soluções recebidas por cada região, os parâmetros estatísticos das regiões, a melhor solução de cada região, a melhor solução global, as estatísticas globais e as mensagens trocadas. Todos esses dados são séries temporais discretas. Quanto ao sistema de banco de dados, nas versões anteriores era utilizado o Sistema Gerenciador de Banco de Dados (SGDB) \textbf{PostgreSQL}. Para a versão atual foi escolhido o \textbf{Cassandra}\footnote{https://cassandra.apache.org/}. Essa escolha se deu pois a biblioteca \textit{akka-cluster} já possui um \textit{plugin} para \textit{journaling} e persistência do estado distribuído da aplicação, e também por ser um SGDB adequado à implementação de sistemas distribuídos. Por simplicidade de configuração e manutenção, foi feita a opção por utilizar um único sistema de banco de dados.

% não entendi as duas últimas frases do parágrafo. Explicar melhor!!

Para executar a arquitetura no \textit{HPC} do CEFET-MG é necessário preparar um ambiente que é complexo, alocar os recursos computacionais, prover arquivos de configuração para o banco de dados, limpar os arquivos temporários que permaneceram nos nós de execuções passadas, iniciar e popular o banco com as tabelas, executar o experimento, extrair esses dados e, por fim, copiar os \textit{logs} da execução. Sobretudo, é necessário garantir que todo experimento inicie sob as mesmas condições, de modo a evitar qualquer viés na coleta dos dados. Para configurar o ambiente, executar e armazenar os dados é necessário produzir uma série de \textit{scripts} de configuração que seguem o padrão do escalonador do \textit{HPC}, no caso do CEFET-MG, o SLURM.

Uma vez alcançados todos estes passos que dizem respeito ao desenvolvimento tecnológico do problema proposto, há que efetivamente executar a bateria de experimentos propostos para por à prova cada uma das hipóteses. Antes disso é necessário formular as hipóteses estatísticas e verificar as premissas para cada um dos conjuntos de dados. Baseado nas premissas, é possível escolher os testes estatísticos apropriados (paramétricos ou não), o nível de significância, o poder do teste e o tamanho da amostra. Baseado nesse planejamento é possível executar os experimentos, coletar e caracterizar os dados utilizando o arcabouço da estatística descritiva e, finalmente, submeter cada uma das hipótese formuladas a um teste estatístico visando refutá-las. 

\section{Premissas}
\label{sec:premissas}
% as distribuições dos valores de  funções objetivos não são normais
Nos experimentos conduzidos por  \citeonline{marcus2015} o efeito da cooperação entre os agentes foi avaliado. O autor comparou os melhores valores de função objetivo que a arquitetura produziu em 30 execuções em que os agentes não colaboravam com outras 30 execuções em que a colaboração estava habilitada. \citeonline{pacheco} repetiu parte desses experimentos e realizou comparações para se certificar que as alterações no modelo de comunicação da arquitetura não alterariam o seu comportamento. Ambos os autores se limitaram a fazer comparações visuais utilizando o \textit{boxplot}, e por isso não fizeram nenhum teste de hipótese sobre a amostra. Entretanto, por mera inspeção destes mesmos \textit{boxplot}, é possível perceber que os valores de função objetivo não seguem uma distribuição normal. Portanto, não se pode assumir normalidade da amostra de valores ótimos obtidos pela arquitetura.

% em contrapartida, a amostragem dos tempos de latência podem ser tratados como normais, pelo teorema do limite central
\citeonline{pacheco} avaliou também a escalabilidade da arquitetura, e verificou que utilizando 2 nós no \textit{cluster}, é possível aumentar o número de agentes e observar um aumento proporcional da quantidade de soluções obtidas em um mesmo intervalo de tempo. Entretanto, essa escalabilidade não foi avaliada quando outros nós são adicionados à simulação. Espera-se que o aumento do número de nós possa intensificar a comunicação pela rede, gerando algum atraso nas mensagens. Como será avaliada a latência média, espera-se que a distribuição das médias das latências siga uma distribuição normal pelo teorema do limite central.

% uma execução da arquitetura no cluster de alto desempenho do cefetmg não infuência as próximas execuções
Ao executar uma bateria de experimentos no \textit{HPC} do CEFET-MG, espera-se que uma execução sempre inicie em um ambiente limpo, sem influência de execuções passadas. Parte disso é garantido pelo próprio \textit{script} de execução, que remove todos os arquivos temporários antes de iniciar uma nova execução, e também inicia o banco de dados em um estado inicial.  

% as execuções são numa rede isolada, num ambiente controlado, sofrendo influências somente das tarefas gerenciais do cluster
Dado que as execuções são realizadas em um ambiente isolado, gerenciadas por um escalonador de recursos (no caso do \textit{cluster} do CEFET-MG, é utilizado o SLURM\footnote{https://slurm.schedmd.com/}), é possível presumir que outras tarefas não irão influenciar a execução do D-Optimas, pois não haverá competição por recursos computacionais, tais como memória e processador. Em outras palavras, dado que o \textit{script} da simulação reserva uma certa quantidade de núcleos de processamento e memória, uma execução iniciará e terminará com os mesmos recursos, não sendo escalonada com outras tarefas de outros usuários, dividindo espaço somente com as tarefas gerenciais do escalonador e do sistema operacional. 

% as únicas mensagens que trafegam na rede com alguma relevância são as do d-optimas
Os experimentos serão executados em uma fila do \textit{HPC} do CEFET-MG reservada à pesquisa do Laboratório de Sistemas Inteligentes do CEFET-MG. Os computadores dessa fila estão isolados da rede do restante do \textit{cluster}, portanto, a última premissa que este trabalho assume é que as únicas mensagens que trafegarão na rede com alguma relevância serão as da arquitetura D-Optimas. Além disso, fez-se o melhor esforço para minimizar outros tipos de comunicação (por exemplo, as do sistema de arquivos, que utiliza o protocolo NFS). Assume-se que as mensagens de gerenciamento e monitoramento do escalonador trafegam na mesma rede em que trafegam as mensagens específicas da D-Optimas, não obstante, elas não influenciam de maneira crítica o resultado dos experimentos. Isso é possível de ser verificado utilizando o utilitário de monitoramento do \textit{HPC} do CEFET-MG, o \textbf{Ganglia}\footnote{É possível acessa-lo na rede interna do CEFET-MG através do endereço http://cluster.decom.cefetmg.br}. Nele é possível verificar que o tráfego na rede quando o super-computador está ocioso é mínimo. Além disso, todo o tráfego é direcionado ao nó mestre do \textit{HPC}, que não é diretamente utilizado durante as simulações da arquitetura D-Optimas.

% os relógios das máquinas estão em sincronia
Por fim, é possível presumir que os relógios das máquinas estejam sincronizados. Essa premissa está baseada no fato de que no \textit{HPC} do CEFET-MG os nós estão configurados para sincronizar os relógios com o nó mestre utilizando o \textit{NTP} (\textit{Network Time Protocol}). Eventualmente, pode haver algum atraso entre os relógios de duas máquinas particulares, mas espera-se que esse efeito não seja significante, uma vez que os resultados dos experimentos serão amostrados considerando as médias das latências. 

\section{Experimentos}
\label{sec:experimentos}
Para colocar à prova as hipóteses propostas neste trabalho,  três experimentos computacionais foram previstos. O primeiro visa avaliar a corretude da arquitetura, verificando se as alterações no comportamento das regiões e na comunicação entre os atores supervisores produzem um comportamento de convergência em torno dos valores conhecidos de função objetivo para cada problema. Em outras palavras, deseja-se verificar a hipótese nula de que a média populacional dos valores de função objetivo obtidos pela arquitetura é igual ao valor ótimo conhecido pela literatura, contra a hipótese alternativa de que os valores de função objetivo  obtidos pela  atual versão da arquitetura sejam  diferentes dos valores conhecidos da literatura. 

Para isso, será necessário utilizar um teste de hipótese não paramétrico para uma amostra, uma vez que não é possível assumir normalidade dos valores de função objetivo obtidos pela arquitetura. Neste ponto há uma dificuldade significativa, pois é sabido que o poder dos testes não paramétricos é menor, o que requer amostras maiores, e pela complexidade tecnológica da arquitetura D-Optimas, coletar amostras grandes é muito custoso, ainda que utilizando um \textit{HPC}. 

Além de avaliar o correto comportamento da arquitetura, é necessário avaliar a escalabilidade da arquitetura ao longo de um \textit{cluster}, executando-a em vários nós ao mesmo tempo. Espera-se que ao aumentar a quantidade de nós na simulação, preservando o número de agentes e o limite de regiões, a latência não aumente de maneira significante, bem como não prejudique a quantidade de soluções geradas da arquitetura e nem afete a sua qualidade. Dito de outra maneira, é necessário fazer duas análises de variância para um fator. Deseja-se avaliar a média da latência das trocas de mensagens e a quantidade de soluções produzidas por intervalo de tempo, para diferentes valores do fator número de nós em que a simulação executa. 

Neste experimento o resultado esperado para o modelo proposto de comunicação entre os atores supervisores e os agentes é que não haja diferença estatisticamente significante para os diferentes níveis do fator número de nós no \textit{cluster}, \textit{i.e.}, não há diferença entre executar a arquitetura com dois, três ou mais nós. Um resultado positivo neste quesito daria um indício da resiliência da arquitetura a diferentes cargas e do seu potencial de escalabilidade. 

Por fim, dadas as novas meta-heurísticas que foram adicionadas na atual versão, procura-se verificar, com um número grande de agentes com diferentes estratégias de busca, se os resultados encontrados são melhores que os obtidos por \citeonline{marcus2015}. Em outras palavras, deseja-se verificar a hipótese nula de que a média dos resultados da arquitetura com várias heurísticas e diferentes configurações é melhor do que a média dos resultados com pouca diversidade de estratégias de busca.

Novamente, há um elemento expressivo de estocasticidade neste experimento que tem origem em diferentes fontes. Entre elas destaca-se o fato de cada agente iniciar com um gerador de números aleatórios diferentes, que é utilizado para a tomada de decisão dos algoritmos; as regiões se agruparem de maneira não-determinística; e finalmente o conjunto de soluções dos algoritmos populacionais não ter sido gerado aleatoriamente, mas escolhido de uma ou mais regiões particulares do espaço de busca. Esses elementos de aleatoriedade dificultam a identificação da função de densidade de probabilidade dos valores de função objetivo obtidos pela arquitetura, e portanto impedem o uso de testes paramétricos. Esses fatores levam à necessidade de se coletar amostras grandes, por longos períodos de tempo, para avaliar a arquitetura com um valor de significância razoável (abaixo de 5\%).

\section{Considerações Finais}
O presente capítulo se dedicou a expor a metodologia científica proposta para a realização deste trabalho. Foram apresentadas três hipóteses que fundamentam esse projeto de pesquisa. Destas três, a última hipótese é a mais relevante do ponto de vista científico. A arquitetura D-Optimas pode ser caracterizada como uma hiper-heurística, um sistema auto-organizável, dotado de um mecanismo de hibridização dinâmica, capaz de gerar combinações e encadeamentos de meta-heurísticas adaptadas às propriedades particulares de cada problema. Além disso, ela é configurável e extensível, permitindo a fácil adição de problemas combinatórios, de otimização irrestrita ou restrita. Além disso, há o fato do sistema ser construído sobre um arcabouço complexo de sistemas distribuídos.  Todos esses fatores tornam a tarefa de estudá-lo, compreendê-lo e testar hipóteses sobre ele um trabalho relevante.

Fez-se aqui também um esforço em levantar as várias premissas que contornam a arquitetura. Um sistema distribuído sofre influência de diversos fatores, incluindo as possíveis falhas na rede, a sincronia entre os relógios dos nós, a carga em cada computador. Todos esses fatores tornam a atividade de replicar e depurar erros bastante complexa. 

Deste modo, o desenvolvimento do trabalho foi feito de maneira criteriosa, testando cada nova funcionalidade, cada meta-heurística separadamente. Algumas destas validações estarão presentes no \autoref{chap:exp_preliminares} e \autoref{chap:exp_diversidade}, ao se fazer a análise da estatística descritiva dos resultados do experimento. O capítulo seguinte se dedicará a apresentar os detalhes do desenvolvimento, principalmente no que diz respeito a nova topologia da arquitetura, adequada para funcionar como um sistema distribuído, e a nova dinâmica das regiões. 